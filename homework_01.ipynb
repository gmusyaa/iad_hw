{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_upCOEI3Upu"
   },
   "source": [
    "# Основы глубинного обучения, майнор ИАД\n",
    "\n",
    "## Домашнее задание 1. Введение в PyTorch. Полносвязные нейронные сети.\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 01.10.2023\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 15.10.2023\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 20.10.2023\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Максимально допустимая оценка за работу — 10 баллов. За каждый день просрочки снимается 1 балл. Сдавать задание после жёсткого дедлайна сдачи нельзя.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
    "\n",
    "Итогова оценка считается как\n",
    "$$\n",
    "min(task_1, task_2)*0.8 + max(task_1, task_2)*0.2\n",
    "$$\n",
    "\n",
    "где task_1 и task_2 - оценки за первое и второе заданиее соответсвенно.\n",
    "Также, за домашнее задание выставляется 0, если не сделано нулевое или третье задание.\n",
    "### О задании\n",
    "\n",
    "В этом задании вам предстоит предсказывать год выпуска песни (**задача регрессии**) по некоторым звуковым признакам: [данные](https://archive.ics.uci.edu/ml/datasets/yearpredictionmsd). В ячейках ниже находится код для загрузки данных. Обратите внимание, что обучающая и тестовая выборки располагаются в одном файле, поэтому НЕ меняйте ячейку, в которой производится деление данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "RI_eoe063VaP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NgSZeU-7vgj",
    "outputId": "bf328cf3-2c32-4f57-fcca-b3801412e2d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-20 19:18:06--  https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\n",
      "Распознаётся archive.ics.uci.edu (archive.ics.uci.edu)… 128.195.10.252\n",
      "Подключение к archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: нет данных\n",
      "Сохранение в: «data.txt.zip»\n",
      "\n",
      "data.txt.zip            [   <=>              ] 201,24M  6,38MB/s    за 36s     \n",
      "\n",
      "2023-10-20 19:18:43 (5,61 MB/s) - «data.txt.zip» сохранён [211011981]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O data.txt.zip https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "DSVJZzkJ7zZE",
    "outputId": "488c6de3-e897-463b-945e-a6752c113f63",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>49.94357</td>\n",
       "      <td>21.47114</td>\n",
       "      <td>73.07750</td>\n",
       "      <td>8.74861</td>\n",
       "      <td>-17.40628</td>\n",
       "      <td>-13.09905</td>\n",
       "      <td>-25.01202</td>\n",
       "      <td>-12.23257</td>\n",
       "      <td>7.83089</td>\n",
       "      <td>...</td>\n",
       "      <td>13.01620</td>\n",
       "      <td>-54.40548</td>\n",
       "      <td>58.99367</td>\n",
       "      <td>15.37344</td>\n",
       "      <td>1.11144</td>\n",
       "      <td>-23.08793</td>\n",
       "      <td>68.40795</td>\n",
       "      <td>-1.82223</td>\n",
       "      <td>-27.46348</td>\n",
       "      <td>2.26327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.73215</td>\n",
       "      <td>18.42930</td>\n",
       "      <td>70.32679</td>\n",
       "      <td>12.94636</td>\n",
       "      <td>-10.32437</td>\n",
       "      <td>-24.83777</td>\n",
       "      <td>8.76630</td>\n",
       "      <td>-0.92019</td>\n",
       "      <td>18.76548</td>\n",
       "      <td>...</td>\n",
       "      <td>5.66812</td>\n",
       "      <td>-19.68073</td>\n",
       "      <td>33.04964</td>\n",
       "      <td>42.87836</td>\n",
       "      <td>-9.90378</td>\n",
       "      <td>-32.22788</td>\n",
       "      <td>70.49388</td>\n",
       "      <td>12.04941</td>\n",
       "      <td>58.43453</td>\n",
       "      <td>26.92061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.95714</td>\n",
       "      <td>31.85602</td>\n",
       "      <td>55.81851</td>\n",
       "      <td>13.41693</td>\n",
       "      <td>-6.57898</td>\n",
       "      <td>-18.54940</td>\n",
       "      <td>-3.27872</td>\n",
       "      <td>-2.35035</td>\n",
       "      <td>16.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>3.03800</td>\n",
       "      <td>26.05866</td>\n",
       "      <td>-50.92779</td>\n",
       "      <td>10.93792</td>\n",
       "      <td>-0.07568</td>\n",
       "      <td>43.20130</td>\n",
       "      <td>-115.00698</td>\n",
       "      <td>-0.05859</td>\n",
       "      <td>39.67068</td>\n",
       "      <td>-0.66345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.24750</td>\n",
       "      <td>-1.89837</td>\n",
       "      <td>36.29772</td>\n",
       "      <td>2.58776</td>\n",
       "      <td>0.97170</td>\n",
       "      <td>-26.21683</td>\n",
       "      <td>5.05097</td>\n",
       "      <td>-10.34124</td>\n",
       "      <td>3.55005</td>\n",
       "      <td>...</td>\n",
       "      <td>34.57337</td>\n",
       "      <td>-171.70734</td>\n",
       "      <td>-16.96705</td>\n",
       "      <td>-46.67617</td>\n",
       "      <td>-12.51516</td>\n",
       "      <td>82.58061</td>\n",
       "      <td>-72.08993</td>\n",
       "      <td>9.90558</td>\n",
       "      <td>199.62971</td>\n",
       "      <td>18.85382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.97020</td>\n",
       "      <td>42.20998</td>\n",
       "      <td>67.09964</td>\n",
       "      <td>8.46791</td>\n",
       "      <td>-15.85279</td>\n",
       "      <td>-16.81409</td>\n",
       "      <td>-12.48207</td>\n",
       "      <td>-9.37636</td>\n",
       "      <td>12.63699</td>\n",
       "      <td>...</td>\n",
       "      <td>9.92661</td>\n",
       "      <td>-55.95724</td>\n",
       "      <td>64.92712</td>\n",
       "      <td>-17.72522</td>\n",
       "      <td>-1.49237</td>\n",
       "      <td>-7.50035</td>\n",
       "      <td>51.76631</td>\n",
       "      <td>7.88713</td>\n",
       "      <td>55.66926</td>\n",
       "      <td>28.74903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6         7   \\\n",
       "0  2001  49.94357  21.47114  73.07750   8.74861 -17.40628 -13.09905 -25.01202   \n",
       "1  2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   8.76630   \n",
       "2  2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940  -3.27872   \n",
       "3  2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   5.05097   \n",
       "4  2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409 -12.48207   \n",
       "\n",
       "         8         9   ...        81         82        83        84        85  \\\n",
       "0 -12.23257   7.83089  ...  13.01620  -54.40548  58.99367  15.37344   1.11144   \n",
       "1  -0.92019  18.76548  ...   5.66812  -19.68073  33.04964  42.87836  -9.90378   \n",
       "2  -2.35035  16.07017  ...   3.03800   26.05866 -50.92779  10.93792  -0.07568   \n",
       "3 -10.34124   3.55005  ...  34.57337 -171.70734 -16.96705 -46.67617 -12.51516   \n",
       "4  -9.37636  12.63699  ...   9.92661  -55.95724  64.92712 -17.72522  -1.49237   \n",
       "\n",
       "         86         87        88         89        90  \n",
       "0 -23.08793   68.40795  -1.82223  -27.46348   2.26327  \n",
       "1 -32.22788   70.49388  12.04941   58.43453  26.92061  \n",
       "2  43.20130 -115.00698  -0.05859   39.67068  -0.66345  \n",
       "3  82.58061  -72.08993   9.90558  199.62971  18.85382  \n",
       "4  -7.50035   51.76631   7.88713   55.66926  28.74903  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.txt.zip', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9a-eJUG35C3"
   },
   "source": [
    "Мы вывели кусок данных, чтобы понять, насколько они пригодны для работы без изменений. Здесь ясно, что сомнительно дальше с такими данными работать, потому что как минимум есть отрицательные значения, которые не отмасштабированы, кроме того еще сразу бросается в глаза совсем разная размерность, где-то видим реально большие числа, а где-то 0.075. Ясно, что будем скейлить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "n4wnRJT1778j"
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values\n",
    "\n",
    "train_size = 463715\n",
    "X_train = X[:train_size, :]\n",
    "y_train = y[:train_size]\n",
    "X_test = X[train_size:, :]\n",
    "y_test = y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_386JE_o5gOd"
   },
   "source": [
    "## Задание 0. (0 баллов, но при невыполнении максимум за все задание &mdash; 0 баллов)\n",
    "\n",
    "Мы будем использовать RMSE как метрику качества. Для самого первого бейзлайна обучите `Ridge` регрессию из `sklearn`. Кроме того, посчитайте качество при наилучшем константном прогнозе.\n",
    "\n",
    "Для выполнения данного задания (и всех последующих) предобработайте данные.\n",
    "\n",
    "1. Зафиксируйте random_seed везде где только возможно. Вам предоставлена функция для этого, однако вы можете дополнить ее своими дополнениями\n",
    "2. Обучите StandertScaler и предобработайте ваши данные. В следующих заданиях можете использовать другой scaler или вообще отказаться от него\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "lkfkXylb8U-O"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler_target = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE на ridge регрессии: 9.510160820470437\n",
      "RMSE на константной модели: 10.863228020678134\n"
     ]
    }
   ],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train_s = scaler_target.fit_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "ridge_model = Ridge(random_state=42)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "ridge_pred = ridge_model.predict(X_test_scaled)\n",
    "rmse_for_model = mean_squared_error(y_test, ridge_pred, squared=False)\n",
    "\n",
    "best_constant = np.mean(y_train)\n",
    "best_constant_pred = np.full_like(y_test, fill_value=best_constant)\n",
    "best_rmse_metric = mean_squared_error(y_test, best_constant_pred, squared=False)\n",
    "\n",
    "print(rmse_for_model, best_rmse_metric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDHAnIkS8vNY"
   },
   "source": [
    "## Задание 1. (максимум 10 баллов)\n",
    "\n",
    "Закрепите свои знания о том, как pytorch работает с обратным распространением ошибки, проделав следующие шаги:\n",
    "\n",
    "1. Создайте модель линейной регрессии, которая будет состоять только из одного Linear слоя.\n",
    "2. Напишите цикл обучения вашей линейной регрессии. В нем реализуйте подсчет функции потерь, сделайте шаг градиентного спуска. Запрещено использовать готовые оптимизаторы и loss-функции из библиотеки pytorch. Для подсчета градиента воспользуйтесь методом backward.\n",
    "3. Запустите обучение на 10 эпохах, после каждой проверяйте значение целевой метрики на тестовой выборке.\n",
    "4. Выведите на экран графики метрики и значения функции потерь на тестовой и обучающей выборке.\n",
    "\n",
    "В данном задании нет цели побить какой-то порог по метрике. Ваша задача - убедиться в том, что ваш рукописный цикл обучения работает. Для ускорения вычислений и обучения модели можете брать только срез данных, а не весь датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "LxnT6G1J-apf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a1a616024347749e8a494fa02f9e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 => Train loss: 144.4832, Test loss: 120.7355, Test RMSE: 10.9880\n",
      "Epoch 2/10 => Train loss: 120.8621, Test loss: 112.9283, Test RMSE: 10.6268\n",
      "Epoch 3/10 => Train loss: 113.5523, Test loss: 108.9331, Test RMSE: 10.4371\n",
      "Epoch 4/10 => Train loss: 109.1868, Test loss: 105.3451, Test RMSE: 10.2638\n",
      "Epoch 5/10 => Train loss: 106.1634, Test loss: 103.6242, Test RMSE: 10.1796\n",
      "Epoch 6/10 => Train loss: 103.9362, Test loss: 101.3023, Test RMSE: 10.0649\n",
      "Epoch 7/10 => Train loss: 102.2356, Test loss: 100.5998, Test RMSE: 10.0299\n",
      "Epoch 8/10 => Train loss: 100.9053, Test loss: 98.8354, Test RMSE: 9.9416\n",
      "Epoch 9/10 => Train loss: 99.8478, Test loss: 98.7313, Test RMSE: 9.9364\n",
      "Epoch 10/10 => Train loss: 98.9995, Test loss: 97.2414, Test RMSE: 9.8611\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(X_train.shape[1], 1))\n",
    "model.to(device)\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train_s, dtype=torch.float32)\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "mse_train, mse_test, rmse_train, rmse_test = [], [], [], []\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    model.train()\n",
    "    y_pred = model(X_train_t.to(device))\n",
    "    loss = torch.mean((y_train_t.to(device) - y_pred) ** 2)\n",
    "    loss.backward()\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= 0.1 * param.grad\n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_test = model(X_test_t.to(device))\n",
    "        \n",
    "        pred_test_inv = scaler_target.inverse_transform(pred_test.cpu().numpy().reshape(-1, 1)).squeeze()\n",
    "        pred_test_inv = torch.tensor(pred_test_inv, dtype=torch.float32)\n",
    "        \n",
    "        y_pred_inv = scaler_target.inverse_transform(y_pred.cpu().numpy().reshape(-1, 1)).squeeze()\n",
    "        y_pred_inv = torch.tensor(y_pred_inv, dtype=torch.float32)\n",
    "        \n",
    "        loss_test = torch.mean((y_test_t.to(device).squeeze() - pred_test_inv.to(device)) ** 2)\n",
    "        loss_train = torch.mean((torch.Tensor(y_train).to(device) - y_pred_inv.to(device)) ** 2)\n",
    "        \n",
    "        mse_train.append(loss_train.item())\n",
    "        mse_test.append(loss_test.item())\n",
    "        rmse_train.append(torch.sqrt(loss_train).item())\n",
    "        rmse_test.append(torch.sqrt(loss_test).item())\n",
    "        \n",
    "        print(f'Epoch {epoch}/{epochs} => Train loss: {loss_train.item():.4f}, Test loss: {loss_test.item():.4f}, Test RMSE: {torch.sqrt(loss_test).item():.4f}')\n",
    "        \n",
    "fig, ax = plt.subplots(figsize=(12, 4), nrows=1, ncols=2)\n",
    "\n",
    "ax[0].plot(range(epochs), mse_train, label='MSE train')\n",
    "ax[0].plot(range(epochs), mse_test, label='MSE test')\n",
    "ax[0].set_title('Значение функции потерь от эпохи')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('MSE')\n",
    "\n",
    "ax[1].plot(range(epochs), rmse_train)\n",
    "ax[1].plot(range(epochs), rmse_test)\n",
    "ax[1].set_title('Значение метрики от эпохи')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('RMSE')\n",
    "\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6ilBKYt6OdD"
   },
   "source": [
    "## Задание 2. (максимум 10 баллов)\n",
    "\n",
    "Реализуйте обучение и тестирование нейронной сети для предоставленного вам набора данных. Соотношение между полученным значением метрики на тестовой выборке и баллами за задание следующее:\n",
    "\n",
    "- $\\text{RMSE} \\le 9.00 $ &mdash; 4 балла\n",
    "- $\\text{RMSE} \\le 8.90 $ &mdash; 6 баллов\n",
    "- $\\text{RMSE} \\le 8.80 $ &mdash; 8 баллов\n",
    "- $\\text{RMSE} \\le 8.75 $ &mdash; 10 баллов\n",
    "\n",
    "Есть несколько правил, которых вам нужно придерживаться:\n",
    "\n",
    "- Весь пайплайн обучения должен быть написан на PyTorch. При этом вы можете пользоваться другими библиотеками (`numpy`, `sklearn` и пр.), но только для обработки данных. То есть как угодно трансформировать данные и считать метрики с помощью этих библиотек можно, а импортировать модели из `sklearn` и выбивать с их помощью требуемое качество &mdash; нельзя. Также нельзя пользоваться библиотеками, для которых сам PyTorch является зависимостью.\n",
    "\n",
    "- Мы никак не ограничиваем ваш выбор архитектуры модели, но скорее всего вам будет достаточно полносвязной нейронной сети.\n",
    "\n",
    "- Для обучения запрещается использовать какие-либо иные данные, кроме обучающей выборки.\n",
    "\n",
    "- Ансамблирование моделей запрещено.\n",
    "\n",
    "### Полезные советы:\n",
    "\n",
    "- Очень вряд ли, что у вас с первого раза получится выбить качество на 10 баллов, поэтому пробуйте разные архитектуры, оптимизаторы и значения гиперпараметров. В идеале при запуске каждого нового эксперимента вы должны менять что-то одно, чтобы точно знать, как этот фактор влияет на качество.\n",
    "\n",
    "- Не забудьте, что для улучшения качества модели вам поможет **нормировка таргета**.\n",
    "\n",
    "- Тот факт, что мы занимаемся глубинным обучением, не означает, что стоит забывать про приемы, использующиеся в классическом машинном обучении. Так что обязательно проводите исследовательский анализ данных, отрисовывайте нужные графики и не забывайте про масштабирование и подбор гиперпараметров.\n",
    "\n",
    "- Вы наверняка столкнетесь с тем, что ваша нейронная сеть будет сильно переобучаться. Для нейросетей существуют специальные методы регуляризации, например, dropout ([статья](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)) и weight decay ([блогпост](https://towardsdatascience.com/weight-decay-l2-regularization-90a9e17713cd)). Они, разумеется, реализованы в PyTorch. Попробуйте поэкспериментировать с ними.\n",
    "\n",
    "- Если вы чего-то не знаете, не гнушайтесь гуглить. В интернете очень много полезной информации, туториалов и советов по глубинному обучению в целом и по PyTorch в частности. Но не забывайте, что за скатанный код без ссылки на источник придется ответить по всей строгости!\n",
    "\n",
    "- Если вы сразу реализуете обучение на GPU, то у вас будет больше времени на эксперименты, так как любые вычисления будут работать быстрее. Google Colab предоставляет несколько GPU-часов (обычно около 8-10) в сутки бесплатно.\n",
    "\n",
    "- Чтобы отладить код, можете обучаться на небольшой части данных или даже на одном батче. Если лосс на обучающей выборке не падает, то что-то точно идет не так!\n",
    "\n",
    "- Пользуйтесь утилитами, которые вам предоставляет PyTorch (например, Dataset и Dataloader). Их специально разработали для упрощения разработки пайплайна обучения.\n",
    "\n",
    "- Скорее всего вы захотите отслеживать прогресс обучения. Для создания прогресс-баров есть удобная библиотека `tqdm`.\n",
    "\n",
    "- Быть может, вы захотите, чтобы графики рисовались прямо во время обучения. Можете воспользоваться функцией [clear_output](http://ipython.org/ipython-doc/dev/api/generated/IPython.display.html#IPython.display.clear_output), чтобы удалять старый график и рисовать новый на его месте.\n",
    "\n",
    "**ОБЯЗАТЕЛЬНО** рисуйте графики зависимости лосса/метрики на обучающей и тестовой выборках в зависимости от времени обучения. Если обучение занимает относительно небольшое число эпох, то лучше рисовать зависимость от номера шага обучения, если же эпох больше, то рисуйте зависимость по эпохам. Если проверяющий не увидит такого графика для вашей лучшей модели, то он в праве снизить баллы за задание.\n",
    "\n",
    "**ВАЖНО!** Ваше решение должно быть воспроизводимым. Если это не так, то проверяющий имеет право снизить баллы за задание. Чтобы зафиксировать random seed, воспользуйтесь функцией из предыдущего задания.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZW0gMe3vT8u"
   },
   "source": [
    "Вы можете придерживаться любой адекватной струкуры кода, но мы советуем воспользоваться сигнатурами функций, которые приведены ниже. Лучше всего, если вы проверите ваши предсказания ассертом: так вы убережете себя от разных косяков, например, что вектор предсказаний состоит из всего одного числа. В любом случае, внимательно следите за тем, для каких тензоров вы считаете метрику RMSE. При случайном или намеренном введении в заблуждение проверяющие очень сильно разозлятся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/mariagorshkova/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmashgorshkova\u001b[0m (\u001b[33mggggggggggg57\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mariagorshkova/Downloads/wandb/run-20231020_200133-3wfwu8c7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ggggggggggg57/pytorch-demo/runs/3wfwu8c7' target=\"_blank\">graceful-wildflower-2</a></strong> to <a href='https://wandb.ai/ggggggggggg57/pytorch-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ggggggggggg57/pytorch-demo' target=\"_blank\">https://wandb.ai/ggggggggggg57/pytorch-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ggggggggggg57/pytorch-demo/runs/3wfwu8c7' target=\"_blank\">https://wandb.ai/ggggggggggg57/pytorch-demo/runs/3wfwu8c7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13803546beee4c1abb9766d547add162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.9207994937896729\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5b83ac3b1d4b239424990df6fd9a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.890425682067871\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15070d35a3724f72baf18165a1b0c8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train loss: 1.0053998231887817\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0f9698450046c8862abe14ed726605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.822441101074219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968f3073514a4a4a9aa89efa9e3fea88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, train loss: 1.0691218376159668\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f321ec3bfd04174b69869ee67aecb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.810803413391113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a96c07f24040a9ab7cb6e694e383d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, train loss: 1.0344053506851196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3a6620de6c4a0092bcc62c0d7666c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.780805587768555\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2784fb018e204065b4c62d91ea49ae6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, train loss: 0.6909733414649963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0c2242904948c382a33ae8c82c4626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.788739204406738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc39752328c4661b89a34aa8f398a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, train loss: 0.6310718655586243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede526d1813a4d9eb30b1c6dbf7f8ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.794276237487793\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0154802e220e4dbab7489b78d0b93649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, train loss: 0.6303645968437195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f993913a29bc41e18bcd404b744ded98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.786593437194824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ebbef7ef5744b8fb0875811f0d78a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.5939772725105286\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1545dd58c8264a4d8599e795c48242a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.772175788879395\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c54e0e6251847819b4f5bf0270e05f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train loss: 0.7229723930358887\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbb19ef9f94490a964934c10b329156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.771110534667969\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79690464e1954623882e8de20e058121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, train loss: 0.7054359316825867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0873fcf04e0a44809453088e1799cbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.771783828735352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21943c5d404044c9b83b0e4762d1808b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, train loss: 0.9469027519226074\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bad802440c64a38aedf8ec4c7de7cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.768394470214844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898f8cda77ac43f4a27f5a2d0522054d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, train loss: 0.7737125158309937\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045036d10bd5448cb1cc9eb69ab4e913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.769405364990234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfc4ea1b26746899a6745bb49bb6319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, train loss: 0.7560169696807861\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8f5d4ea7d54478a0bbed1cfac4ece5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.76965045928955\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495d638de70d46eeb8debcd0e99444cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, train loss: 0.8025519847869873\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3924b0a273c4baeac9becac420a6fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.765301704406738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc538c1133340548729772c6aa0d555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, train loss: 0.6351394057273865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ef1b3004b64b56adb4014ca4f03a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 8.762657165527344\n"
     ]
    }
   ],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "set_random_seed(12098)\n",
    "\n",
    "koef = np.std(y_train)\n",
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values\n",
    "train_size = 463715\n",
    "X_train = X[:train_size, :]\n",
    "y_train = y[:train_size]\n",
    "X_test = X[train_size:, :]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "xscaler = StandardScaler()\n",
    "xscaler.fit(X_train)\n",
    "X_train = xscaler.transform(X_train)\n",
    "X_test = xscaler.transform(X_test)\n",
    "yscaler = StandardScaler()\n",
    "yscaler.fit(y_train.reshape(-1, 1))\n",
    "y_train = yscaler.transform(y_train.reshape(-1, 1))\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.x[idx, :], dtype=torch.float), torch.tensor(self.y[idx], dtype=torch.float))\n",
    "\n",
    "train_set = Dataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4)\n",
    "\n",
    "test_set = Dataset(X_test, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=51630)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(90, 150),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(150, 1)\n",
    ")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "!pip install wandb --upgrade --quiet\n",
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "wandb.init(project=\"pytorch-demo\")\n",
    "wandb.watch(model);\n",
    "\n",
    "def train(model, optimizer,criterion, train_loader, test_loader, name, koef):\n",
    "\n",
    "    for X_train, y_train in tqdm(train_loader):    \n",
    "      val_loss = [] \n",
    "      y_pred = model(X_train)       \n",
    "      loss = torch.sqrt(criterion(y_pred, y_train))      \n",
    "      loss.backward()                                \n",
    "      optimizer.step()                               \n",
    "      optimizer.zero_grad() \n",
    "      val_loss.append(loss.detach().numpy()*koef)      \n",
    "    wandb.log({f\"train loss {name}\": np.mean(val_loss)})\n",
    "    print(f\"Epoch: {epoch}, train loss: {np.mean(val_loss)}\")\n",
    "\n",
    "def test(model, criterion, test_loader, name):\n",
    "    val_loss = []                                  \n",
    "    with torch.no_grad():                          \n",
    "      for X_test, y_test in tqdm(test_loader): \n",
    "        y_pred = torch.squeeze(model(X_test))   \n",
    "        y_pred = torch.from_numpy(yscaler.inverse_transform(y_pred.detach().numpy().reshape(-1, 1)))\n",
    "        y_pred = torch.squeeze(y_pred)     \n",
    "        loss = torch.sqrt(criterion(y_pred, y_test))  \n",
    "        val_loss.append(loss.numpy())           \n",
    "          \n",
    "    wandb.log({f\"{name}\": np.mean(val_loss)})\n",
    "\n",
    "    print(f\"test loss: {np.mean(val_loss)}\")\n",
    "    \n",
    "set_random_seed(12098)\n",
    "loader = torch.utils.data.DataLoader(train_set, batch_size=40, shuffle = True)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(90, 250),\n",
    "    nn.BatchNorm1d(250),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(250, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(100),\n",
    "    nn.Linear(100, 1)\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.004, amsgrad = True)\n",
    "\n",
    "for epoch in range(7):\n",
    "  train(model, optimizer,criterion, loader, test_loader,'лучшая модель', koef)\n",
    "\n",
    "  test(model, criterion, test_loader, 'лучшая модель')\n",
    "\n",
    "precise_optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(8):\n",
    "  train(model, precise_optimizer,criterion, loader, test_loader,'лучшая модель', koef)\n",
    "  test(model, criterion, test_loader, 'лучшая модель')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ссылочка на графики:\n",
    "https://wandb.ai/ggggggggggg57/pytorch-demo/reports/---Vmlldzo1NzMyNjU5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZglNls8l-1VZ"
   },
   "source": [
    "я прошу прощения, что таким макаром все, делаю из больницы с температурой 38.7......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bine9EES6TIn"
   },
   "source": [
    "## Задание 3. (0 баллов, но при невыполнении максимум за все задание &mdash; 0 баллов)\n",
    "\n",
    "Напишите небольшой отчет о том, как вы добились полученного качества: какие средства использовали и какие эксперименты проводили. Подробно расскажите об архитектурах и значениях гиперпараметров, а также какие метрики на тесте они показывали. Чтобы отчет был зачтен, необходимо привести хотя бы 3 эксперимента."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала я провела обучение простой двуслойной модели и экспериментировала с разным количеством нейронов, а именно 150, 250 и 400. В итоге выяснилось, что модель с 400 нейронами демонстрировала небольшое преимущество в процессе обучения на более дальних эпохах, но в целом разница между ними была невелика.\n",
    "\n",
    "После этого я решила использовать модель с функцией активации ReLU и 250 нейронами в среднем слое для всех последующих экспериментов.\n",
    "\n",
    "Далее я занялась настройкой оптимального размера пакета (batch size) и рассматривала значения от 5 до 100. Оказалось, что размер пакета 20 показал наилучшие результаты. Дополнительно, я провела тестирование размеров пакета от 20 до 40 с интервалом в 5 единиц, и наилучший результат был достигнут при размере пакета 40.\n",
    "\n",
    "Затем я перешла к подбору оптимальной скорости обучения (learning rate, LR) и протестировала значения 0.1, 0.01, 0.001 и 0.0001. Выяснилось, что оптимальное значение LR находится где-то между 0.01 и 0.001, и лучший результат достигнут при LR равной 0.005.\n",
    "\n",
    "Итоговая архитектура модели включает в себя еще один слой с функцией активации ReLU и применение батч-нормализации на всех слоях. При этом с использованием найденных оптимальных гиперпараметров, ошибка была снижена до 8.74, а после дополнительной оптимизации с использованием метода стохастического градиентного спуска (SGD) с LR равной 0.001, качество модели было улучшено до 8.72."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
